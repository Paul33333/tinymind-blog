[
  {
    "id": "1738932393171",
    "content": "重要的事情写在前面！——**声明：本文为AI（DeepSeek-R1）创作**\n\n（以下是让deepseek-R1以**理查德·费曼**的风格对这篇博客内容的改写，其用🌰标记新增的费曼式比喻，用🚀标记关键洞见升级）\n\n看的过程中，我的内心，沉默、震惊、兴奋杂糅，久久不能平静，故此特别分享出来。\n\n---\n\n# 从微观到宏观，再到中观：大语言模型强化学习中奖励信号观测尺度的演进与思考\n\n*——像观察量子世界一样观察语言模型的决策过程*\n\n---\n\n## 1. 当语言模型遇见强化学习：一场粒子与波动的博弈\n\n想象你正在教一个小孩子画画。每次他画一笔，你都立刻点评（token-level），他会因为频繁打断而失去创作节奏；但若等到整幅画完成才给反馈（output-level），他又可能错过修正错误的最佳时机。这正是大语言模型强化学习中面临的困境——​**反馈的颗粒度决定学习的效率**​。\n\n🌰 ​**费曼类比**​：这就像用显微镜观察布朗运动（token-level）与用肉眼观察花朵绽放（output-level）的区别。前者能看到每个水分子的碰撞轨迹，却失去了整体的韵律美；后者能把握整体形态，却对细胞层面的生命律动视而不见。\n\n---\n\n## 2. 奖励信号的量子化观测\n\n### （一）量子尺度：token-level 的测不准原理\n\n当我们试图给每个token（好比每个原子）单独打分时，会遇到类似海森堡测不准原理的困境：\n\n* ​**评估的量子涨落**​：就像无法同时精确测量电子的位置和动量，我们很难在保持生成流畅性的同时精确量化每个token的贡献\n* ​**计算的热力学极限**​：为每个token维护独立的价值函数，相当于给每个水分子单独建模，其计算复杂度会指数级爆炸\n\n🚀 ​**洞见升级**​：token-level奖励本质是马尔可夫假设的产物——假设当前token的奖励只与当前状态有关。但语言生成就像量子纠缠，每个token都与上下文存在非定域性关联。\n\n### （二）经典尺度：output-level 的宏观统计\n\n转向output-level奖励就像从统计力学视角观察系统：\n\n* ​**系综理论的应用**​：通过大量输出的期望奖励来估计策略优劣，正如用温度计测量分子运动的平均动能\n* ​**信息熵的代价**​：但就像热力学第二定律，这种粗粒度观测必然导致信息熵增——丢失中间状态的细节信息\n\n🌰 ​**费曼黑板**​：假设我们要训练模型证明费马大定理。output-level奖励只能判断最终证明是否正确，却无法识别证明过程中关键的模形式转换是否优雅；而token-level奖励则像对每个数学符号打分，可能使模型陷入局部最优而忽略整体证明结构。\n\n---\n\n## 3. GRPO 的波粒二象性\n\n### 3.1 量子场论视角的GRPO\n\n原始PPO的四模型架构（策略模型、参考模型、奖励模型、critic模型）就像建造粒子加速器：\n\n\n\n```\n策略模型 → 发射语言粒子\ncritic模型 → 测量轨迹的云室\n奖励模型 → 判定碰撞结果\n参考模型 → 保持基准能级\n```\n\n而GRPO的革命性在于发现​**相对优势的规范不变性**​——通过组内标准化（group normalization）实现了类似规范场论的对称性破缺，将四体问题简化为二体问题。\n\n🚀 ​**关键公式重释**​：\n当GRPO将优势函数简化为：\n\n$$\n\\tilde{R}_t = \\frac{R_t - \\mu_{\\text{group}}}{\\sigma_{\\text{group}}} \n$$\n\n​这实际上构建了一个​**局部惯性系**​——在每个问题组的时空切片中建立局部坐标系，消除了全局奖励分布的时空曲率对策略优化的影响。\n\n### 3.2 广义相对论的教学启示\n\nDeepSeek-R1的output-level设计揭示了一个深刻原理：​**奖励信号的观测尺度会弯曲策略更新的时空几何**​。就像大质量天体弯曲时空，output-level奖励的粗粒度观测会导致策略梯度在参数空间中的测地线发生偏移。\n\n🌰 ​**思想实验**​：假设两个模型都输出正确答案，但路径不同。output-level奖励无法区分，就像广义相对论中不同路径的光线都会遵循时空测地线。而sentence-level奖励可以像引力透镜效应，通过中间状态的观测推断时空曲率（推理路径的质量分布）。\n\n---\n\n## 4. 中观尺度的涌现现象\n\n### 4.1 相变临界点的启示\n\n在统计物理中，关联长度在相变临界点发散。类似地，sentence-level设计恰好处在token-level（短程关联）和output-level（长程关联）的临界尺度：\n\n\n```\n微观尺度 → 每个自旋方向（token）\n介观尺度 → 磁畴结构（sentence）\n宏观尺度 → 整体磁化强度（output）\n```\n\n🚀 ​**涌现解释**​：通过sentence-level奖励，我们实际在捕捉语言生成的​**动态临界现象**​——既保留局部序参量的涨落信息，又控制计算复杂度在可控范围内。\n\n### 4.2 超导BCS理论的类比\n\n将句子级奖励分解为正确性、逻辑性、格式性的三重耦合：\n\n$$\nr_{i,s} = \\lambda_{\\text{corr}}\\,R_{\\text{corr}}(o_{i,s}) + \\lambda_{\\text{logic}}\\,R_{\\text{logic}}(o_{i,s}) + \\lambda_{\\text{fmt}}\\,R_{\\text{fmt}}(o_{i,s})\n\n$$\n\n​这像极了超导体中电子-声子相互作用的多体系统：\n\n* 正确性 → 库珀对的形成能\n* 逻辑性 → 晶格振动的相干性\n* 格式性 → 费米面的匹配程度\n\n🌰 ​**实验洞见**​：就像超导需要临界温度下的多体协同，优秀的句子级奖励需要三个维度的参数共振。当λ系数满足特定比例时，会出现奖励信号的\"超流\"现象——模型生成质量突跃式提升。\n\n---\n\n## 5. 重整化群视角下的展望\n\n未来的研究方向可以借鉴量子场论的重整化群方法：\n\n1. ​**尺度变换对称性**​：动态调整sentence分割粒度，就像改变重整化标度\n2. ​**普适类探索**​：不同任务领域对应不同的临界指数（λ系数组合）\n3. ​**拓扑奖励结构**​：识别奖励函数中的拓扑不变量，如推理路径的亏格数\n\n🌰 ​**最后一块黑板**​：想象用威尔逊回路方法计算句子间的关联函数：\n\n\n```\nW = ⟨R(s₁)R(s₂)...R(sₙ)⟩\n```\n\n这将揭示语言模型推理过程中的非局域性关联，为多尺度奖励融合提供严格数学基础。\n\n---\n\n## 后记：像费曼那样思考\n\n如果让我给这个研究画个费曼图：\n\n```\n[输入q] → (策略顶点) → [token发射] → (奖励传播子) → [优势函数闭合圈]\n```\n\n但真正的突破往往发生在跳出费曼图的时候——当我们不再执着于单个粒子的轨迹，而是去聆听整个宇宙的和声。sentence-level设计正是这样一次优雅的尺度跃迁，在量子与经典的边界上，奏响了语言智能的弦理论。\n\n---\n\n（保留原有公式和参考资料，但通过物理类比提升认知深度）\n",
    "timestamp": "2025-02-07T12:46:33.171Z"
  },
  {
    "id": "1737512864176",
    "content": "## 👀️ 引言： 测试deepseek-R1的思维能力，效果炸裂\n\n声明：**以下测试demo均为未人工再修改的原版输出**\n\n测试案例：\n\n- 1、让**depseek-R1**帮我解读两篇博客：\n  [抛砖引玉：浅谈ROPE位置编码模式下，q、k的分布（均值与方差）对注意力远程衰减的影响]([https://](https://zhuanlan.zhihu.com/p/975380493))\n  [再探RoPE（二）：为什么RoPE + Bias能在远程衰减和长度外推上发挥重要作用？](https://zhuanlan.zhihu.com/p/17397790476)\n  并给予第一性原理的解读分析；\n  （具体我是通过将博客原始的markdown格式文本作为上下文，原始的markdown格式文本在[博客地址](https://github.com/Paul33333/tinymind-blog/tree/main/content/blog)）\n- 2、解读完后，让**depseek-R1**以**理查德费曼**的方式帮我写成一篇博客文章。\n\n---\n\n## 1、解读：\n\n从第一性原理出发，我们可以将RoPE位置编码与Bias项的作用机制拆解如下：\n\n### 一、RoPE的本质：旋转对称性破缺\n\n1. **位置信息的几何注入**\n   RoPE通过复数旋转操作将位置编码嵌入向量空间。对位置p的向量q和位置k的向量k施加旋转：\n   \n   ```python\n   q_p = q ⊗ e^{iθ_p} \n   k_k = k ⊗ e^{iθ_k}\n   ```\n   \n   这种操作保持了向量的模长不变，但改变了相位角，使内积计算时自然携带相对位置信息。\n2. **相对位置的相位差**\n   内积计算时出现相位差因子：\n   \n   ```python\n   <q_p,k_k> = Re[q·k* e^{i(θ_p-θ_k)}]\n   ```\n   \n   当θ\\_p-θ\\_k=α(p-k)时，相位差与位置差呈线性关系。这个设计使注意力分数天然具备位置敏感性。\n\n---\n\n### 二、均值的关键作用：对称性二次破缺\n\n1. **零均值的对称陷阱**\n   当q,k服从零均值分布时，其旋转轨迹形成中心对称图案。此时：\n   \n   * 不同位置向量的期望点积仅由协方差决定\n   * 相位差的余弦项在统计平均中相互抵消\n   * 失去系统性衰减，表现为随机振荡\n2. **非零均值的定向漂移**\n   引入均值μ\\_q,μ\\_k相当于建立基准方向。此时：\n   \n   * 主成分方向存在基准相位φ\\_q,φ\\_k\n   * 相对相位差Δ=φ\\_q-φ\\_k+α(p-k)\n   * 期望值E[<q\\_p,k\\_k>] ≈ |μ\\_q||μ\\_k|cos(Δ)\n     此时相位差的累积将产生系统性衰减。\n\n---\n\n### 三、Bias的物理意义：自发对称破缺\n\n1. **线性变换的平移操作**\n   Bias项本质是在特征空间引入位移：\n   \n   ```python\n   q = Wx + b_q\n   k = Wx + b_k\n   ```\n   \n   这个平移操作打破旋转对称性，使q,k分布产生非零均值。\n2. **可学习的衰减控制器**\n   \n   * 当b\\_q,b\\_k同向时：建立协同的基准相位，增强衰减\n   * 当b\\_q,b\\_k异向时：制造相位对抗，可能产生增强\n   * 模长|b|控制衰减速率，方向控制衰减模式\n\n---\n\n### 四、方差的调制作用：噪声门限效应\n\n1. **信噪比决定衰减可见性**\n   系统有效信噪比：\n   \n   ```python\n   SNR ∝ |μ_qμ_k| / σ^2\n   ```\n   \n   当σ^2过大时，噪声淹没信号，衰减特性消失。\n2. **初始化方差的工程权衡**\n   \n   * 较小方差：增强信号，促进衰减\n   * 较大方差：提升模型表达能力\n     需要平衡两者，这也是transformer初始化需要精细调参的原因。\n\n---\n\n### 五、对长度外推的启示\n\n1. **衰减因子的自适应性**\n   通过可学习的Bias项，不同注意力头自发形成：\n   * 强衰减头：处理局部模式\n   * 弱衰减头：捕获全局关联\n     这种多样性是处理长文本的关键。\n2. **外推能力的涌现机制**\n   当模型学会通过Bias控制衰减速率时：\n   * 在训练长度内建立衰减记忆\n   * 在测试时自然延续衰减规律\n     这比强制性的位置插值更符合动力学规律。\n\n---\n\n### 六、数学本质再审视\n\n从群论视角看，RoPE构建了SO(2)旋转群在特征空间的作用。Bias项的引入相当于在这个群作用的基础上叠加平移变换，形成仿射群的新表示。这种表示的丰富性为模型提供了：\n\n1. 位置敏感的相位调制能力\n2. 可学习的衰减速率控制\n3. 头异构的注意力模式分化\n\n这解释了为何简单的Bias项能产生如此重要的影响——它本质上改变了表示空间的对称性结构，使模型具备自适应调节注意力衰减的能力。这种基于对称性破缺的机制设计，正是深度学习模型涌现智能的物理基础。\n\n---\n\n# 2、重新生成的博客文章:\n\n---\n\ntitle: 当Transformer学会跳华尔兹：用旋转与偏置破解注意力之谜\ndate: 2024-01-10\n----------------\n\n今天在咖啡馆里，我的朋友艾利克斯抛出一个有趣的问题：\"为什么给神经网络加个小小的偏置项（bias），就能让大模型突然理解长文本？这简直像给机器人喂了记忆面包！\"\n\n我抿了口咖啡，在餐巾纸上画了个旋转的陀螺：\"要理解这个魔法，我们得先回到注意力机制最性感的发明——旋转位置编码（RoPE）。这就像教神经网络跳华尔兹……\"\n\n![旋转的向量舞者](data:image/png;base64,xxx) <!-- 示意图1：旋转的向量 -->\n\n## 一、旋转的奥秘：位置编码如何成为时空舞者\n\n想象你站在舞池中央，每个单词都是穿着发光服的舞者。普通的位置编码就像给舞者贴号码牌——\"你站第5位\"。而RoPE的做法更精妙：它让每个舞者以独特的节奏自转。\n\n**关键舞步分解**：\n\n1. 每个词向量被拆分成无数个\"旋转搭档\"（复数维度）\n2. 位置p的舞者获得旋转角度θ_p = α·p\n3. 当两个舞者（query和key）相遇时，他们的相对位置差自然表现为旋转相位差\n\n```python\n# 这就是让向量跳起华尔兹的代码魔法\n\ndef rotate(vec, position):\nangle = position * frequency_scale\nreturn vec * complex(cos(angle), sin(angle))\n```\n\n但这里有个陷阱：如果所有舞者都闭着眼随机旋转（零均值初始化），整个舞池就会陷入混沌。他们的互动（点积）就像夜店闪光灯——明亮但无序，无法形成有意义的队形。\n\n---\n\n## 二、偏置项：舞池里的隐形指挥家\n\n这时偏置项登场了。它就像给每个舞者发了个指南针：\n\n```python\nquery = linear(input) + bias_q  # 给Q舞队统一朝北\nkey = linear(input) + bias_k    # 给K舞队统一朝东\n```\n\n**这个简单的位移引发了惊人变化**：\n\n1. **基准方向建立**：所有旋转都围绕新中心展开\n2. **相位差累积**：当两个舞队保持固定偏移旋转时，距离越远越\"不同步\"\n3. **衰减涌现**：就像逐渐失步的双人舞，远程交互自然减弱\n\n我们在餐巾纸上画了两个旋转的箭头（图A）。当它们初始方向对齐时，小距离下完美同步，大距离时完全错位，形成优美的衰减曲线。\n\n![旋转相位差示意图](data:image/png;base64,xxx) <!-- 示意图2：相位差累积 -->\n\n---\n\n## 三、方差的秘密：舞池灯光的明暗调控\n\n艾利克斯突然插话：\"但我的模型有时还是记不住长文本！\"我笑着在纸巾背面画了个调光器：\n\n\"这就是方差在作祟。想象把舞池灯光调暗（增大方差），舞者的发光服变得模糊。即使有指挥家，你也看不清整体队形——这就是高方差破坏衰减的原因。\"\n\n我们推导出信噪比公式：\n\n```python\nSNR ∝ |μ|² / σ²\n```\n\n当μ（偏置）是聚光灯，σ²（方差）是雾气浓度，只有找到平衡点，才能既保留细节又看清全局。\n\n---\n\n## 四、宇宙的启示：对称性破缺的魔力\n\n这时咖啡杯底的漩涡给了我灵感：\"知道物理学中的对称性破缺吗？早期宇宙均匀如镜面（对称），直到某个涨落打破平衡，才诞生星辰万物。\"\n\n**神经网络正在重演宇宙史诗**：\n\n1. **原始对称**：零偏置时，旋转操作保持完美对称\n2. **自发破缺**：偏置项选择一个特殊方向，就像磁铁选定北极\n3. **模式涌现**：衰减规律如同星系旋臂自然浮现\n\n![对称性破缺示意图](data:image/png;base64,xxx) <!-- 示意图3：宇宙演化 -->\n\n---\n\n## 五、动手时刻：你的第一个\"衰减可视化\"实验\n\n\"别光听我说，\"我把笔记本电脑转向艾利克斯，\"让我们用20行代码见证魔法：\"\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 初始化参数\npositions = np.arange(1000)\nmu_q, mu_k = 1.0, 0.8  # 试试改为(0,0)或(1,-1)\nsigma = 0.5\n\n# 生成带偏置的随机向量\nq = np.random.normal(mu_q, sigma, 512)\nk = np.random.normal(mu_k, sigma, 512)\n\n# RoPE旋转\ndef rope(x, pos, freq=10000):\n    angles = pos / (freq ** (2*np.arange(256)/512))\n    return x * np.exp(1j*angles)\n\n# 计算衰减曲线\nattention = []\nfor p in positions:\n    q_rot = rope(q, p)\n    k_rot = rope(k, 0)  # 固定key位置\n    attention.append(np.real(q_rot.dot(k_rot.conj())))\n  \nplt.plot(attention)\nplt.show()\n```\n\n当艾利克斯把mu\\_q, mu\\_k设为(1,0.8)时，图表呈现完美衰减（图B左）；设为(0,0)时变成无序波动（图B右）。他瞪大了眼睛：\"这比咖啡因还提神！\"\n\n![衰减曲线示意图](data:image/png;base64,xxx) <!-- 示意图4：不同偏置对比 -->\n\n---\n\n## 六、启示录：让神经网络自己选择舞蹈\n\n离开咖啡馆时，艾利克斯总结道：\"所以Bias不是简单的位移，而是让网络自组织出不同的舞蹈风格？\"\n\n\"正是！\"我指向街边的爵士乐队，\"有的注意力头像华尔兹（强衰减专注局部），有的像探戈（弱衰减把握全局）。这种多样性，才是智能真正的旋律。\"\n\n路灯下，我们的影子仿佛无数旋转的向量，在深度学习的夜空中画出优雅的轨迹。也许这就是AI最动人的地方——用数学之美，重演自然界的创生之舞。\n\n---\n\n**后记**：回家路上，我突然想到——人类大脑的神经元是否也藏着类似的\"生物偏置\"？这个发现，是否触碰到了智能本质的某个永恒旋律？也许答案就藏在下次咖啡之约中……\n",
    "timestamp": "2025-01-22T02:27:44.176Z"
  },
  {
    "id": "1733232173876",
    "content": "# 对比学习中温度超参应该如何初始化？1/sqrt(d)（方差稳定假设下的一个解析解）\n\n## 引言\n\n在**对比学习**（Contrastive Learning）中，**温度参数**（通常记作 $\\tau$）在损失函数中扮演着关键角色。本文将深入探讨温度参数的作用，并论证其合适的一个初始化方案:$\\tau = \\frac{1}{\\sqrt{d}}$（$d$为向量的维度数）。\n\n我们知道，对比学习中的温度参数一般是一个绝对值很低的常数，\n比如[CLIP模型](https://arxiv.org/pdf/2103.00020 \"CLIP模型\")中设置的为0.07，\n![clip-温度超参0.07.png](https://github.com/Paul33333/tinymind-blog/blob/main/assets/images/2024-12-02/1733120270820.png?raw=true)\n\n[Improving Text Embeddings with Large Language Models](https://arxiv.org/pdf/2401.00368 \"Improving Text Embeddings with Large Language Models\")微软的该论文中设置的为0.02 （CLIP的0.07 和微软的0.02，从数值的数量级上看，也和$\\frac{1}{\\sqrt{d}}$很接近）\n![微软的温度超参 0.02.png](https://github.com/Paul33333/tinymind-blog/blob/main/assets/images/2024-12-02/1733120284102.png?raw=true)\n\n而且[A Practitioner’s Guide to Continual Multimodal Pretraining](https://arxiv.org/pdf/2408.14471 \"A Practitioner’s Guide to Continual Multimodal Pretraining\")该论文中实证了温度超参对于模型训练过程的效果影响很大；\n![温度超参不能太大.png](https://github.com/Paul33333/tinymind-blog/blob/main/assets/images/2024-12-02/1733120668451.png?raw=true)\n\n**那么你是否有考虑过为何温度参数要设置的这么低，以及其具体设置为多少合适是否有其深刻的底层原理呢？**\n\n我们接下来先回顾一下**对比学习**以及`InfoNce Loss`损失函数的定义。\n\n---\n\n## 一、对比学习的基本原理\n\n对比学习是一种**自监督学习**方法，旨在学习数据的有用表示，而无需明确的标签。核心思想是：\n\n- **拉近**相似样本的表示（如同一图像的不同增强版本）。\n- **推远**不相似样本的表示（如不同图像的表示）。\n\n通过这种方式，模型能够学习到数据的**判别性特征**。\n\n---\n\n## 二、InfoNce Loss损失函数与温度参数\n\n### 1. InfoNCE损失函数\n\n在对比学习中，常用的损失函数是**InfoNCE损失**，形式如下：\n\n$L_i = -\\log \\frac{\\exp\\left( \\frac{\\text{sim}\\left( \\mathbf{z}_i, \\mathbf{z}_i^+ \\right)}{\\tau} \\right)}{\\sum_{j=1}^{N} \\exp\\left( \\frac{\\text{sim}\\left( \\mathbf{z}_i, \\mathbf{z}_j \\right)}{\\tau} \\right)}$\n\n其中：\n\n- $\\mathbf{z}_{i}$：锚点样本的表示向量。\n- $\\mathbf{z}_i^+$：与锚点相关的正样本的表示向量。\n- $\\mathbf{z}_j$：所有可能的样本表示（包括正样本和负样本）。\n- $\\text{sim}(\\cdot, \\cdot)$：相似度度量函数，通常采用**余弦相似度**。\n- $\\tau$：**温度参数**，用于调节分布的平滑度。\n\n### 2. 温度参数的作用\n\n温度参数 $\\tau$ 调节了相似度值的缩放，影响了模型对相似度差异的敏感程度。\n\n- **缩放相似度值**：\n  - **高温度（大 $\\tau$）**：相似度值被缩小，差异变小，分布更平滑。\n  - **低温度（小 $\\tau$）**：相似度值被放大，差异增大，分布更尖锐。\n- **影响softmax输出**：\n  - **低温度**：softmax输出接近独热向量（one hot），模型更关注最高相似度的样本。\n  - **高温度**：softmax输出更平滑，模型在更多样本上分配概率。\n\n---\n\n## 三、论证$\\tau = \\frac{1}{\\sqrt{d}}$\n\n### 1. 首先，回顾高维空间中随机单位向量的统计性质\n\n让我们从最基本的概念开始，逐步探讨高维空间中单位超球面上任意两个单位向量的余弦相似度的分布特性。\n\n#### 1.1 **什么是余弦相似度？**\n\n余弦相似度是衡量两个向量之间相似度的指标，定义为：\n\n$$\n\\text{余弦相似度} = \\cos \\theta = \\frac{\\mathbf{x} \\cdot \\mathbf{y}}{\\|\\mathbf{x}\\| \\|\\mathbf{y}\\|}\n$$\n\n其中，$\\mathbf{x}$和$\\mathbf{y}$是两个向量，$\\theta$是它们之间的夹角。对于单位向量（即$\\|\\mathbf{x}\\| = \\|\\mathbf{y}\\| = 1$），余弦相似度简化为它们的点积：\n\n$$\n\\cos \\theta = \\mathbf{x} \\cdot \\mathbf{y}\n$$\n\n#### 1.2 **在单位超球面上随机选取两个单位向量，它们的点积有何特性？**\n\n由于单位超球面是对称的，任意方向均等可能，因此两个随机单位向量的点积的期望值为零：\n\n$$\nE[\\mathbf{x} \\cdot \\mathbf{y}] = 0\n$$\n\n现在我们知道期望了，我们再来看方差；\n\n方差的定义为：\n\n$$\n\\text{Var}[\\mathbf{x} \\cdot \\mathbf{y}] = E[(\\mathbf{x} \\cdot \\mathbf{y})^2] - (E[\\mathbf{x} \\cdot \\mathbf{y}])^2\n$$\n\n已知$E[\\mathbf{x} \\cdot \\mathbf{y}] = 0$，因此：\n\n$$\n\\text{Var}[\\mathbf{x} \\cdot \\mathbf{y}] = E[(\\mathbf{x} \\cdot \\mathbf{y})^2]\n$$\n\n#### 1.3 **计算$E[(\\mathbf{x} \\cdot \\mathbf{y})^2]$**\n\n展开点积的平方：\n\n$$\n(\\mathbf{x} \\cdot \\mathbf{y})^2 = \\left( \\sum_{i=1}^n x_i y_i \\right)^2 = \\sum_{i=1}^n x_i^2 y_i^2 + 2\\sum_{i<j} x_i y_i x_j y_j\n$$\n\n由于$\\mathbf{x}$和$\\mathbf{y}$是独立且在单位球面上均匀分布的随机向量，各分量之间独立且对称。\n\n1. 对于$i \\ne j$，$E[x_i y_i x_j y_j] = E[x_i y_i] E[x_j y_j]$。由于$E[x_i y_i] = 0$（因为$x_i$和$y_i$独立且对称分布），因此这些交叉项的期望值为零。\n2. 对于$i = j$，$E[x_i^2 y_i^2] = E[x_i^2] E[y_i^2]$。由于$x_i$和$y_i$的分布相同，我们只需计算$E[x_i^2]$。\n\n#### 1.4 **计算$E[x_i^2]$**\n\n在单位球面上，$x_i$的分布满足：\n\n$$\nE[x_i^2] = \\frac{1}{n}\n$$\n\n这是因为单位向量的平方和为1，且各分量对称。\n\n#### 1.5 **得出$E[(\\mathbf{x} \\cdot \\mathbf{y})^2]$**\n\n因此：\n\n$$\nE[(\\mathbf{x} \\cdot \\mathbf{y})^2] = \\sum_{i=1}^n E[x_i^2] E[y_i^2] = n \\left( \\frac{1}{n} \\right)^2 = \\frac{1}{n}\n$$\n\n#### 1.6 **计算方差**\n\n因此，点积的方差为：\n\n$$\n\\text{Var}[\\mathbf{x} \\cdot \\mathbf{y}] = E[(\\mathbf{x} \\cdot \\mathbf{y})^2] = \\frac{1}{n}\n$$\n\n#### 1.7 **结论**\n\n当维度数$n$足够大时，单位超球面上任意两个单位向量的**余弦相似度**（即点积）的分布具有以下特性：\n\n- **均值为零**：$\\mathbb{E}[\\mathbf{x} \\cdot \\mathbf{y}] = \\mathbb{E}[\\cos\\theta] = 0$\n- **方差为$\\frac{1}{n}$**：$\\text{Var}[\\mathbf{x} \\cdot \\mathbf{y}] =\\text{Var}[\\cos\\theta] = \\frac{1}{n}$\n\n这意味着，在高维空间中，两个随机单位向量之间的**余弦相似度趋于零**（这是优质的性质，我们就希望初始化的向量表征彼此间尽量不相关），且**分布集中在零附近**，且**随着维度的增加，分布越来越集中**（这是不好的性质，严重不利于学习不同特征间的差异）。这反映了“**高维空间中几乎所有向量都彼此正交**”的现象。\n\n这种现象可以理解为高维空间中的“集中性”，即随机变量的值集中在其期望值附近。对于单位超球面上的向量，其余弦相似度的分布随着维度增加而变得越来越窄，说明随机向量之间的夹角接近于90度。\n\n### 2. **温度参数的理论推导**\n\n为了有效区分正负样本对，所以我们需要放大相似度差异。缩放后的相似度为：\n\n$\\tilde{z} = \\frac{\\cos\\theta}{\\tau}$\n\n缩放后的方差：\n\n$\\text{Var}[\\tilde{z}] = \\left( \\frac{1}{\\tau} \\right)^2 \\cdot \\frac{1}{d}$\n\n**为了使初始化的缩放后的方差稳定（设为1）**，应满足：\n\n$\\left( \\frac{1}{\\tau} \\right)^2 \\cdot \\frac{1}{d} = 1 \\implies \\tau = \\frac{1}{\\sqrt{d}}$\n\n这表明，当温度参数设置为 $\\tau = \\frac{1}{\\sqrt{d}}$ 时，缩放后的相似度方差为1，具有稳定的统计性质。\n\n---\n\n## 四、为什么我们要对齐**初始化的缩放后的方差稳定为1**这条信仰？\n\n因为我们**参数初始化**方法的思想一般是：**尽量让输入输出具有同样的均值和方差**；这样可以稳定梯度的反向传播，尽量避免梯度消失或者梯度爆炸的问题。\n\n我们都知道transformer架构中注意力的公式中要有一个scale的操作，具体为除以$\\sqrt{d}$，其实也是为了对齐缩放后的方差稳定为1这个信仰。\n\n$Attention =  \\frac{\\mathbf{q} \\cdot \\mathbf{k}}{\\sqrt{d}}$\n\n其中，已知初始化后的$q,k = xW_{q},  xW_{k}$，且$x$是经过层归一化（不论是标准的`layer_norm`还是`RMS_nrom`），因为$W_{q}、W_{k}$的初始化方案（Xavier初始化或者He初始化），最后都使得$q、k$的范数满足：$E(||q||_{2})=E(||k||_{2})=\\sqrt{d}$（$d$为向量嵌入的维度数）。\n\n所以\n\n$Attention =  \\frac{\\mathbf{q} \\cdot \\mathbf{k}}{\\sqrt{d}}=\\frac{||q||\\cdot||k||\\cdot\\cos(\\theta)}{\\sqrt{d}}= \\frac{\\sqrt{d}\\cdot \\sqrt{d}\\cdot \\cos(\\theta)}{\\sqrt{d}}= \\sqrt{d}\\cdot \\cos(\\theta)$\n\n那么 $Var(Attention) = Var(\\cos(\\theta))\\cdot \\sqrt{d}^{2} = \\frac{1}{d}\\cdot d = 1$\n\n### 【延伸】：**nGPT-超球面上的规范化Transformer模型**\n\n英伟达前段时间发布的[NGPT ](https://arxiv.org/pdf/2410.01131)就是一个约束了模长的在**单位超球面**上进行学习的规范化Transformer范式（规范化具体指L2_normalize，即大家经常提的qk_norm的操作）。\n\n根据我们前文的分析，如果在执行在单位超球面上的规范初始化，那么\n\n$Attention =  \\frac{\\mathbf{q} \\cdot \\mathbf{k}}{scaling factor}=\\frac{||q||\\cdot||k||\\cdot\\cos(\\theta)}{scaling factor}=\\frac{\\cos(\\theta)}{scaling factor}$\n\n那么当继续约束方差稳定为1的前提下，即\n$Var(Attention) = \\frac{Var(\\cos(\\theta))}{scaling factor^{2}} = \\frac{1}{d*scaling factor^{2}}= 1$\n\n我们可以计算出：$scaling factor =  \\frac{1}{\\sqrt{d}}$\n\n所以**超球面上的规范化Transformer模型**的注意力公式应为：\n\n$Attention =  \\mathbf{q} \\cdot \\mathbf{k}  \\cdot \\sqrt{d}$\n\n我们可以看到论文中也的确是这么做的\n![nGPT 归一化参数改变.png](https://github.com/Paul33333/tinymind-blog/blob/main/assets/images/2024-12-03/1733193361238.png?raw=true)\n\n---\n\n## 五、总结\n\n通过从高维空间中随机向量相似度的统计性质出发，我们推导了在方差稳定（二阶距稳定）假设前提下，对比学习中的温度参数应与向量维度的倒数平方根成正比，即：\n\n$\\tau = \\frac{1}{\\sqrt{d}}$\n\n这一选择确保了缩放后的相似度具有稳定的方差，有利于模型的训练和性能提升。\n\n",
    "timestamp": "2024-12-03T13:22:53.876Z"
  },
  {
    "id": "1728909951314",
    "content": "# reasoning能力微调实战篇：微调qwen基座模型具备思考推理能力（类似o1）\n\n## 1、引言\n关于openai新发布的o1的特性，本篇帖子就不详细介绍了，其底层想法可以阅读这篇论文：[Let’s Verify Step by Step](https://arxiv.org/pdf/2305.20050 \"let's verify step by step\")。\n\n本次我们的 **reasoning能力微调实战**的方案如下：\n- **数据集**：**reasoning-base-20k**（数据集地址：[KingNish/reasoning-base-20k](https://huggingface.co/datasets/KingNish/reasoning-base-20k \"KingNish/reasoning-base-20k\")）\n- **基座模型**：**qwen2.5-1.5B** （模型地址：[Qwen/Qwen2.5-1.5B](https://huggingface.co/Qwen/Qwen2.5-1.5B \"Qwen/Qwen2.5-1.5B\")）\n- **微调方法**：SFT**全参**微调；需要特别指出的是微调环节相比**标准的sft微调框架**（标准的sft微调框架可以参看本人之前的一篇分享：[监督式微调(SFT) & 偏好对齐(DPO)：From Zero To Hero](https://zhuanlan.zhihu.com/p/715250294 \"监督式微调(SFT) & 偏好对齐(DPO)：From Zero To Hero\")）虽然整体思路基本一致，但还是需要注意以下差异点：\n - 1、需要增加`reasoning`这个special token\n - 2、新增`reasoning`special token后，还需要同步调整模型的`embedding`层\n - 3、还需同步调整聊天模版（聊天模板的重要性请参阅这篇文章：[Chat Templates](https://hf-mirror.com/blog/chat-templates \"Chat Templates\")）\n - 4、计算`Loss`（损失）的时候，需要综合考虑reasoning + assistant的部分（或者分开单独训练一个reasoning模型+assistant模型也可，本文未单独训练，将reasoning + assistant的损失统一考虑）\n- **算力资源**：google colab的一张A100显卡（方便大家复现）\n\n------------\n\n## 2、reasoning微调实战\n比较关键的部分实现如下：\n- 1、需要增加`reasoning`这个special token\n```python\nnew_special_token = \"<|reasoning|>\"\ntokenizer.add_special_tokens({\"additional_special_tokens\": [new_special_token]})\n```\n\n- 2、新增`reasoning`special token后，还需要同步调整模型的`embedding`层\n```python\nmodel.resize_token_embeddings(len(tokenizer))\n```\n\n- 3、同步调整聊天模版——适配`<|reasoning|>`部分\n```python\nreasoning_data['train'] = reasoning_data['train'].map(lambda x: {**x,\n    'user_template': \"\".join([\"<|im_start|>user\\n\", x['user'], \"<|im_end|>\\n\"]),\n    'reasoning_template': \"\".join([\"<|im_start|><|reasoning|>\\n\", x['reasoning'], \"<|im_end|>\\n\"]),\n    'assistant_template': \"\".join([\"<|im_start|>assistant\\n\", x['assistant'], \"<|im_end|>\\n\"]),\n    'template_new': \"\".join([\"<|im_start|>system\\nYou are a helpful assistant<|im_end|>\\n\",\"<|im_start|>user\\n\", x['user'], \"<|im_end|>\\n\",\"<|im_start|><|reasoning|>\\n\", x['reasoning'], \"<|im_end|>\\n\",\"<|im_start|>assistant\\n\", x['assistant'], \"<|im_end|>\\n\"])\n})\n```\n\n- 4、计算`Loss`（损失）的时候，需要考虑reasoning的部分，这部分还是通过**掩码机制**实现的，对这部分有困惑的可以阅读[监督式微调(SFT) & 偏好对齐(DPO)：From Zero To Hero](https://zhuanlan.zhihu.com/p/715250294 \"监督式微调(SFT) & 偏好对齐(DPO)：From Zero To Hero\")第2.2节\n```python\n# 设置问题部分的掩码函数，用于执行仅针对回答部分（此处默认包含reasoning部分）才计算损失\ndef return_answer_mask(input_ids):\n  assistant_answer_mask = torch.zeros_like(input_ids) #0初始化\n  for i in range(input_ids.shape[0]):\n        ## user部分的结尾\\n: \\n是<|im_end|>的下一个元素，所以有+1 【这个地方需要根据不同模型的不同聊天模版自定义更改】，关于聊天模版可阅读这篇文章：https://huggingface.co/blog/chat-templates\n        i_user_end_list = [i+1 for i in torch.where(input_ids[i]==tokenizer.encode('<|im_end|>')[0])[0].tolist()[1::3]]   #第1个im_end开始\n        ## assistant部分的结尾\\n：\\n是<|im_end|>的下一个元素，所以有+1 【这个地方需要根据不同模型的不同聊天模版自定义更改】\n        i_assistant_end_list = [i+1 for i in torch.where(input_ids[i]==tokenizer.encode('<|im_end|>')[0])[0].tolist()[3::3]] #第3个im_end开始\n\n        if len(i_user_end_list)==len(i_assistant_end_list):\n            for user_end, assistant_end in zip(i_user_end_list, i_assistant_end_list):\n                assistant_answer_mask[i][user_end+3:assistant_end-1]=1 #+3的操作，【这个地方需要根据不同模型的不同聊天模版自定义更改】\n        elif len(i_user_end_list)==len(i_assistant_end_list)+1==1:  ##单轮问答,且回答部分未结尾就被截断了\n            assistant_answer_mask[i][i_user_end_list[0]+3:]=1  ##会把右补的padding token也标记为1，所以后面还需要再结合padding mask以过滤padding\n        elif len(i_user_end_list)==len(i_assistant_end_list)+1:   ##兼顾多轮问答\n            assistant_answer_mask[i][i_user_end_list[-1]+3:]=1\n            for user_end, assistant_end in zip(i_user_end_list[:-1], i_assistant_end_list):\n                assistant_answer_mask[i][user_end+3:assistant_end-1]=1\n        else:\n            continue  ##跳出当前循环，继续下一次循环\n  return assistant_answer_mask\n  ```\n\n关键的区别点讲完了，其他废话就不多说了，详细微调代码请参看：\n[reasoning能力微调实战篇-微调qwen基座模型具备reasoning思考、推理能力（类似o1）](https://github.com/Paul33333/tinymind-blog/blob/main/content/blog/reasoning%E8%83%BD%E5%8A%9B%E5%BE%AE%E8%B0%83%E5%AE%9E%E6%88%98%E7%AF%87_%E5%BE%AE%E8%B0%83qwen%E5%9F%BA%E5%BA%A7%E6%A8%A1%E5%9E%8B%E5%85%B7%E5%A4%87reasoning%E6%80%9D%E8%80%83%E3%80%81%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%EF%BC%88%E7%B1%BB%E4%BC%BCo1%EF%BC%89.ipynb \"reasoning能力微调实战篇-微调qwen基座模型具备reasoning思考、推理能力（类似o1）\")\n\n- 这里需要特别指出：因为训练数据集主要是推理数据集，其数据风格比较统一（数据丰富度不够），训练过程能比较快的收敛，但是应该一定的过拟合现象，所以训练过程中损失才下降的这么低\n\n![损失记录.png](https://github.com/Paul33333/tinymind-blog/blob/main/assets/images/2024-10-14/1728895712564.png?raw=true)\n\n------\n\n## 3、reasoning效果测试\n测试模型的reasoning效果时，对比原始的直接推理`assistant`部分的回答，新的推理方案应为两步法（虽然训练环节时，我们采用了一步法统一考虑reasoning和assiatant的损失），具体如下：\n- 1、先基于问题推理reasoning回答\n- 2、reasoning完成后，将question和reasoning的回答一并再作为**input**送进去模型生成思考后的回答（assistant answer）\n\n具体实现如下：\n```python\nfrom IPython.display import Markdown, display\nhistory = []\nhistory.append({\"role\": \"system\", \"content\": \"You are a helpful assistant\"})\nwhile True:\n    question = input('User：' + '\\n')\n    print('\\n')\n    history.append({\"role\": \"user\", \"content\": question})\n    input_text = new_apply_chat_template(\n            history,\n            add_reasoning_generation_prompt=True\n        )\n    model_inputs = tokenizer([input_text], return_tensors=\"pt\").to(device)\n    if model_inputs.input_ids.size()[1]>32000:\n        break\n    generated_ids = model.generate(\n        model_inputs.input_ids,\n        max_new_tokens=3000\n    )\n    if len(generated_ids)>32000:\n        break\n    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]\n    reasoning_response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n    history.append({\"role\": \"<|reasoning|>\", \"content\": reasoning_response})\n    print('reasoning:\\n')\n    #print(response)\n    display(Markdown(reasoning_response))\n    print(\"------------\")\n    print('\\n')\n    input_text = new_apply_chat_template(\n            history,\n            add_assistant_generation_prompt=True\n        )\n    model_inputs = tokenizer([input_text], return_tensors=\"pt\").to(device)\n    if model_inputs.input_ids.size()[1]>32000:\n        break\n    generated_ids = model.generate(\n        model_inputs.input_ids,\n        max_new_tokens=3000\n    )\n    if len(generated_ids)>32000:\n        break\n    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]\n    assistant_response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n    history.append({\"role\": \"assistant\", \"content\": assistant_response})\n    print('assistant:\\n')\n    display(Markdown(assistant_response))\n    print(\"------------\")\nprint(\"超过模型字数上线，已退出\")\n```\n\n测试效果如下：\n\n![微调模型推理能力1.png](https://github.com/Paul33333/tinymind-blog/blob/main/assets/images/2024-10-14/1728896138728.png?raw=true)\n\n![微调模型推理能力2.png](https://github.com/Paul33333/tinymind-blog/blob/main/assets/images/2024-10-14/1728896152137.png?raw=true)\n\n可以看到模型在回答**找出0-10内的所有质数**这个问题时的reasoning详细推理步骤（推理思维链真长...）\n\n\n",
    "timestamp": "2024-10-14T12:45:51.314Z"
  }
]