[
  {
    "id": "1733232173876",
    "content": "# 对比学习中温度超参应该如何初始化？1/sqrt(d)（方差稳定假设下的一个解析解）\n\n## 引言\n\n在**对比学习**（Contrastive Learning）中，**温度参数**（通常记作 $\\tau$）在损失函数中扮演着关键角色。本文将深入探讨温度参数的作用，并论证其合适的一个初始化方案:$\\tau = \\frac{1}{\\sqrt{d}}$（$d$为向量的维度数）。\n\n我们知道，对比学习中的温度参数一般是一个绝对值很低的常数，\n比如[CLIP模型](https://arxiv.org/pdf/2103.00020 \"CLIP模型\")中设置的为0.07，\n![clip-温度超参0.07.png](https://github.com/Paul33333/tinymind-blog/blob/main/assets/images/2024-12-02/1733120270820.png?raw=true)\n\n[Improving Text Embeddings with Large Language Models](https://arxiv.org/pdf/2401.00368 \"Improving Text Embeddings with Large Language Models\")微软的该论文中设置的为0.02 （CLIP的0.07 和微软的0.02，从数值的数量级上看，也和$\\frac{1}{\\sqrt{d}}$很接近）\n![微软的温度超参 0.02.png](https://github.com/Paul33333/tinymind-blog/blob/main/assets/images/2024-12-02/1733120284102.png?raw=true)\n\n而且[A Practitioner’s Guide to Continual Multimodal Pretraining](https://arxiv.org/pdf/2408.14471 \"A Practitioner’s Guide to Continual Multimodal Pretraining\")该论文中实证了温度超参对于模型训练过程的效果影响很大；\n![温度超参不能太大.png](https://github.com/Paul33333/tinymind-blog/blob/main/assets/images/2024-12-02/1733120668451.png?raw=true)\n\n**那么你是否有考虑过为何温度参数要设置的这么低，以及其具体设置为多少合适是否有其深刻的底层原理呢？**\n\n我们接下来先回顾一下**对比学习**以及`InfoNce Loss`损失函数的定义。\n\n---\n\n## 一、对比学习的基本原理\n\n对比学习是一种**自监督学习**方法，旨在学习数据的有用表示，而无需明确的标签。核心思想是：\n\n- **拉近**相似样本的表示（如同一图像的不同增强版本）。\n- **推远**不相似样本的表示（如不同图像的表示）。\n\n通过这种方式，模型能够学习到数据的**判别性特征**。\n\n---\n\n## 二、InfoNce Loss损失函数与温度参数\n\n### 1. InfoNCE损失函数\n\n在对比学习中，常用的损失函数是**InfoNCE损失**，形式如下：\n\n$L_i = -\\log \\frac{\\exp\\left( \\frac{\\text{sim}\\left( \\mathbf{z}_i, \\mathbf{z}_i^+ \\right)}{\\tau} \\right)}{\\sum_{j=1}^{N} \\exp\\left( \\frac{\\text{sim}\\left( \\mathbf{z}_i, \\mathbf{z}_j \\right)}{\\tau} \\right)}$\n\n其中：\n\n- $\\mathbf{z}_{i}$：锚点样本的表示向量。\n- $\\mathbf{z}_i^+$：与锚点相关的正样本的表示向量。\n- $\\mathbf{z}_j$：所有可能的样本表示（包括正样本和负样本）。\n- $\\text{sim}(\\cdot, \\cdot)$：相似度度量函数，通常采用**余弦相似度**。\n- $\\tau$：**温度参数**，用于调节分布的平滑度。\n\n### 2. 温度参数的作用\n\n温度参数 $\\tau$ 调节了相似度值的缩放，影响了模型对相似度差异的敏感程度。\n\n- **缩放相似度值**：\n  - **高温度（大 $\\tau$）**：相似度值被缩小，差异变小，分布更平滑。\n  - **低温度（小 $\\tau$）**：相似度值被放大，差异增大，分布更尖锐。\n- **影响softmax输出**：\n  - **低温度**：softmax输出接近独热向量（one hot），模型更关注最高相似度的样本。\n  - **高温度**：softmax输出更平滑，模型在更多样本上分配概率。\n\n---\n\n## 三、论证$\\tau = \\frac{1}{\\sqrt{d}}$\n\n### 1. 首先，回顾高维空间中随机单位向量的统计性质\n\n让我们从最基本的概念开始，逐步探讨高维空间中单位超球面上任意两个单位向量的余弦相似度的分布特性。\n\n#### 1.1 **什么是余弦相似度？**\n\n余弦相似度是衡量两个向量之间相似度的指标，定义为：\n\n$$\n\\text{余弦相似度} = \\cos \\theta = \\frac{\\mathbf{x} \\cdot \\mathbf{y}}{\\|\\mathbf{x}\\| \\|\\mathbf{y}\\|}\n$$\n\n其中，$\\mathbf{x}$和$\\mathbf{y}$是两个向量，$\\theta$是它们之间的夹角。对于单位向量（即$\\|\\mathbf{x}\\| = \\|\\mathbf{y}\\| = 1$），余弦相似度简化为它们的点积：\n\n$$\n\\cos \\theta = \\mathbf{x} \\cdot \\mathbf{y}\n$$\n\n#### 1.2 **在单位超球面上随机选取两个单位向量，它们的点积有何特性？**\n\n由于单位超球面是对称的，任意方向均等可能，因此两个随机单位向量的点积的期望值为零：\n\n$$\nE[\\mathbf{x} \\cdot \\mathbf{y}] = 0\n$$\n\n现在我们知道期望了，我们再来看方差；\n\n方差的定义为：\n\n$$\n\\text{Var}[\\mathbf{x} \\cdot \\mathbf{y}] = E[(\\mathbf{x} \\cdot \\mathbf{y})^2] - (E[\\mathbf{x} \\cdot \\mathbf{y}])^2\n$$\n\n已知$E[\\mathbf{x} \\cdot \\mathbf{y}] = 0$，因此：\n\n$$\n\\text{Var}[\\mathbf{x} \\cdot \\mathbf{y}] = E[(\\mathbf{x} \\cdot \\mathbf{y})^2]\n$$\n\n#### 1.3 **计算$E[(\\mathbf{x} \\cdot \\mathbf{y})^2]$**\n\n展开点积的平方：\n\n$$\n(\\mathbf{x} \\cdot \\mathbf{y})^2 = \\left( \\sum_{i=1}^n x_i y_i \\right)^2 = \\sum_{i=1}^n x_i^2 y_i^2 + 2\\sum_{i<j} x_i y_i x_j y_j\n$$\n\n由于$\\mathbf{x}$和$\\mathbf{y}$是独立且在单位球面上均匀分布的随机向量，各分量之间独立且对称。\n\n1. 对于$i \\ne j$，$E[x_i y_i x_j y_j] = E[x_i y_i] E[x_j y_j]$。由于$E[x_i y_i] = 0$（因为$x_i$和$y_i$独立且对称分布），因此这些交叉项的期望值为零。\n2. 对于$i = j$，$E[x_i^2 y_i^2] = E[x_i^2] E[y_i^2]$。由于$x_i$和$y_i$的分布相同，我们只需计算$E[x_i^2]$。\n\n#### 1.4 **计算$E[x_i^2]$**\n\n在单位球面上，$x_i$的分布满足：\n\n$$\nE[x_i^2] = \\frac{1}{n}\n$$\n\n这是因为单位向量的平方和为1，且各分量对称。\n\n#### 1.5 **得出$E[(\\mathbf{x} \\cdot \\mathbf{y})^2]$**\n\n因此：\n\n$$\nE[(\\mathbf{x} \\cdot \\mathbf{y})^2] = \\sum_{i=1}^n E[x_i^2] E[y_i^2] = n \\left( \\frac{1}{n} \\right)^2 = \\frac{1}{n}\n$$\n\n#### 1.6 **计算方差**\n\n因此，点积的方差为：\n\n$$\n\\text{Var}[\\mathbf{x} \\cdot \\mathbf{y}] = E[(\\mathbf{x} \\cdot \\mathbf{y})^2] = \\frac{1}{n}\n$$\n\n#### 1.7 **结论**\n\n当维度数$n$足够大时，单位超球面上任意两个单位向量的**余弦相似度**（即点积）的分布具有以下特性：\n\n- **均值为零**：$\\mathbb{E}[\\mathbf{x} \\cdot \\mathbf{y}] = \\mathbb{E}[\\cos\\theta] = 0$\n- **方差为$\\frac{1}{n}$**：$\\text{Var}[\\mathbf{x} \\cdot \\mathbf{y}] =\\text{Var}[\\cos\\theta] = \\frac{1}{n}$\n\n这意味着，在高维空间中，两个随机单位向量之间的**余弦相似度趋于零**（这是优质的性质，我们就希望初始化的向量表征彼此间尽量不相关），且**分布集中在零附近**，且**随着维度的增加，分布越来越集中**（这是不好的性质，严重不利于学习不同特征间的差异）。这反映了“**高维空间中几乎所有向量都彼此正交**”的现象。\n\n这种现象可以理解为高维空间中的“集中性”，即随机变量的值集中在其期望值附近。对于单位超球面上的向量，其余弦相似度的分布随着维度增加而变得越来越窄，说明随机向量之间的夹角接近于90度。\n\n### 2. **温度参数的理论推导**\n\n为了有效区分正负样本对，所以我们需要放大相似度差异。缩放后的相似度为：\n\n$\\tilde{z} = \\frac{\\cos\\theta}{\\tau}$\n\n缩放后的方差：\n\n$\\text{Var}[\\tilde{z}] = \\left( \\frac{1}{\\tau} \\right)^2 \\cdot \\frac{1}{d}$\n\n**为了使初始化的缩放后的方差稳定（设为1）**，应满足：\n\n$\\left( \\frac{1}{\\tau} \\right)^2 \\cdot \\frac{1}{d} = 1 \\implies \\tau = \\frac{1}{\\sqrt{d}}$\n\n这表明，当温度参数设置为 $\\tau = \\frac{1}{\\sqrt{d}}$ 时，缩放后的相似度方差为1，具有稳定的统计性质。\n\n---\n\n## 四、为什么我们要对齐**初始化的缩放后的方差稳定为1**这条信仰？\n\n因为我们**参数初始化**方法的思想一般是：**尽量让输入输出具有同样的均值和方差**；这样可以稳定梯度的反向传播，尽量避免梯度消失或者梯度爆炸的问题。\n\n我们都知道transformer架构中注意力的公式中要有一个scale的操作，具体为除以$\\sqrt{d}$，其实也是为了对齐缩放后的方差稳定为1这个信仰。\n\n$Attention =  \\frac{\\mathbf{q} \\cdot \\mathbf{k}}{\\sqrt{d}}$\n\n其中，已知初始化后的$q,k = xW_{q},  xW_{k}$，且$x$是经过层归一化（不论是标准的`layer_norm`还是`RMS_nrom`），因为$W_{q}、W_{k}$的初始化方案（Xavier初始化或者He初始化），最后都使得$q、k$的范数满足：$E(||q||_{2})=E(||k||_{2})=\\sqrt{d}$（$d$为向量嵌入的维度数）。\n\n所以\n\n$Attention =  \\frac{\\mathbf{q} \\cdot \\mathbf{k}}{\\sqrt{d}}=\\frac{||q||\\cdot||k||\\cdot\\cos(\\theta)}{\\sqrt{d}}= \\frac{\\sqrt{d}\\cdot \\sqrt{d}\\cdot \\cos(\\theta)}{\\sqrt{d}}= \\sqrt{d}\\cdot \\cos(\\theta)$\n\n那么 $Var(Attention) = Var(\\cos(\\theta))\\cdot \\sqrt{d}^{2} = \\frac{1}{d}\\cdot d = 1$\n\n### 【延伸】：**nGPT-超球面上的规范化Transformer模型**\n\n英伟达前段时间发布的[NGPT ](https://arxiv.org/pdf/2410.01131)就是一个约束了模长的在**单位超球面**上进行学习的规范化Transformer范式（规范化具体指L2_normalize，即大家经常提的qk_norm的操作）。\n\n根据我们前文的分析，如果在执行在单位超球面上的规范初始化，那么\n\n$Attention =  \\frac{\\mathbf{q} \\cdot \\mathbf{k}}{scaling factor}=\\frac{||q||\\cdot||k||\\cdot\\cos(\\theta)}{scaling factor}=\\frac{\\cos(\\theta)}{scaling factor}$\n\n那么当继续约束方差稳定为1的前提下，即\n$Var(Attention) = \\frac{Var(\\cos(\\theta))}{scaling factor^{2}} = \\frac{1}{d*scaling factor^{2}}= 1$\n\n我们可以计算出：$scaling factor =  \\frac{1}{\\sqrt{d}}$\n\n所以**超球面上的规范化Transformer模型**的注意力公式应为：\n\n$Attention =  \\mathbf{q} \\cdot \\mathbf{k}  \\cdot \\sqrt{d}$\n\n我们可以看到论文中也的确是这么做的\n![nGPT 归一化参数改变.png](https://github.com/Paul33333/tinymind-blog/blob/main/assets/images/2024-12-03/1733193361238.png?raw=true)\n\n---\n\n## 五、总结\n\n通过从高维空间中随机向量相似度的统计性质出发，我们推导了在方差稳定（二阶距稳定）假设前提下，对比学习中的温度参数应与向量维度的倒数平方根成正比，即：\n\n$\\tau = \\frac{1}{\\sqrt{d}}$\n\n这一选择确保了缩放后的相似度具有稳定的方差，有利于模型的训练和性能提升。\n\n",
    "timestamp": "2024-12-03T13:22:53.876Z"
  },
  {
    "id": "1728909951314",
    "content": "# reasoning能力微调实战篇：微调qwen基座模型具备思考推理能力（类似o1）\n\n## 1、引言\n关于openai新发布的o1的特性，本篇帖子就不详细介绍了，其底层想法可以阅读这篇论文：[Let’s Verify Step by Step](https://arxiv.org/pdf/2305.20050 \"let's verify step by step\")。\n\n本次我们的 **reasoning能力微调实战**的方案如下：\n- **数据集**：**reasoning-base-20k**（数据集地址：[KingNish/reasoning-base-20k](https://huggingface.co/datasets/KingNish/reasoning-base-20k \"KingNish/reasoning-base-20k\")）\n- **基座模型**：**qwen2.5-1.5B** （模型地址：[Qwen/Qwen2.5-1.5B](https://huggingface.co/Qwen/Qwen2.5-1.5B \"Qwen/Qwen2.5-1.5B\")）\n- **微调方法**：SFT**全参**微调；需要特别指出的是微调环节相比**标准的sft微调框架**（标准的sft微调框架可以参看本人之前的一篇分享：[监督式微调(SFT) & 偏好对齐(DPO)：From Zero To Hero](https://zhuanlan.zhihu.com/p/715250294 \"监督式微调(SFT) & 偏好对齐(DPO)：From Zero To Hero\")）虽然整体思路基本一致，但还是需要注意以下差异点：\n - 1、需要增加`reasoning`这个special token\n - 2、新增`reasoning`special token后，还需要同步调整模型的`embedding`层\n - 3、还需同步调整聊天模版（聊天模板的重要性请参阅这篇文章：[Chat Templates](https://hf-mirror.com/blog/chat-templates \"Chat Templates\")）\n - 4、计算`Loss`（损失）的时候，需要综合考虑reasoning + assistant的部分（或者分开单独训练一个reasoning模型+assistant模型也可，本文未单独训练，将reasoning + assistant的损失统一考虑）\n- **算力资源**：google colab的一张A100显卡（方便大家复现）\n\n------------\n\n## 2、reasoning微调实战\n比较关键的部分实现如下：\n- 1、需要增加`reasoning`这个special token\n```python\nnew_special_token = \"<|reasoning|>\"\ntokenizer.add_special_tokens({\"additional_special_tokens\": [new_special_token]})\n```\n\n- 2、新增`reasoning`special token后，还需要同步调整模型的`embedding`层\n```python\nmodel.resize_token_embeddings(len(tokenizer))\n```\n\n- 3、同步调整聊天模版——适配`<|reasoning|>`部分\n```python\nreasoning_data['train'] = reasoning_data['train'].map(lambda x: {**x,\n    'user_template': \"\".join([\"<|im_start|>user\\n\", x['user'], \"<|im_end|>\\n\"]),\n    'reasoning_template': \"\".join([\"<|im_start|><|reasoning|>\\n\", x['reasoning'], \"<|im_end|>\\n\"]),\n    'assistant_template': \"\".join([\"<|im_start|>assistant\\n\", x['assistant'], \"<|im_end|>\\n\"]),\n    'template_new': \"\".join([\"<|im_start|>system\\nYou are a helpful assistant<|im_end|>\\n\",\"<|im_start|>user\\n\", x['user'], \"<|im_end|>\\n\",\"<|im_start|><|reasoning|>\\n\", x['reasoning'], \"<|im_end|>\\n\",\"<|im_start|>assistant\\n\", x['assistant'], \"<|im_end|>\\n\"])\n})\n```\n\n- 4、计算`Loss`（损失）的时候，需要考虑reasoning的部分，这部分还是通过**掩码机制**实现的，对这部分有困惑的可以阅读[监督式微调(SFT) & 偏好对齐(DPO)：From Zero To Hero](https://zhuanlan.zhihu.com/p/715250294 \"监督式微调(SFT) & 偏好对齐(DPO)：From Zero To Hero\")第2.2节\n```python\n# 设置问题部分的掩码函数，用于执行仅针对回答部分（此处默认包含reasoning部分）才计算损失\ndef return_answer_mask(input_ids):\n  assistant_answer_mask = torch.zeros_like(input_ids) #0初始化\n  for i in range(input_ids.shape[0]):\n        ## user部分的结尾\\n: \\n是<|im_end|>的下一个元素，所以有+1 【这个地方需要根据不同模型的不同聊天模版自定义更改】，关于聊天模版可阅读这篇文章：https://huggingface.co/blog/chat-templates\n        i_user_end_list = [i+1 for i in torch.where(input_ids[i]==tokenizer.encode('<|im_end|>')[0])[0].tolist()[1::3]]   #第1个im_end开始\n        ## assistant部分的结尾\\n：\\n是<|im_end|>的下一个元素，所以有+1 【这个地方需要根据不同模型的不同聊天模版自定义更改】\n        i_assistant_end_list = [i+1 for i in torch.where(input_ids[i]==tokenizer.encode('<|im_end|>')[0])[0].tolist()[3::3]] #第3个im_end开始\n\n        if len(i_user_end_list)==len(i_assistant_end_list):\n            for user_end, assistant_end in zip(i_user_end_list, i_assistant_end_list):\n                assistant_answer_mask[i][user_end+3:assistant_end-1]=1 #+3的操作，【这个地方需要根据不同模型的不同聊天模版自定义更改】\n        elif len(i_user_end_list)==len(i_assistant_end_list)+1==1:  ##单轮问答,且回答部分未结尾就被截断了\n            assistant_answer_mask[i][i_user_end_list[0]+3:]=1  ##会把右补的padding token也标记为1，所以后面还需要再结合padding mask以过滤padding\n        elif len(i_user_end_list)==len(i_assistant_end_list)+1:   ##兼顾多轮问答\n            assistant_answer_mask[i][i_user_end_list[-1]+3:]=1\n            for user_end, assistant_end in zip(i_user_end_list[:-1], i_assistant_end_list):\n                assistant_answer_mask[i][user_end+3:assistant_end-1]=1\n        else:\n            continue  ##跳出当前循环，继续下一次循环\n  return assistant_answer_mask\n  ```\n\n关键的区别点讲完了，其他废话就不多说了，详细微调代码请参看：\n[reasoning能力微调实战篇-微调qwen基座模型具备reasoning思考、推理能力（类似o1）](https://github.com/Paul33333/tinymind-blog/blob/main/content/blog/reasoning%E8%83%BD%E5%8A%9B%E5%BE%AE%E8%B0%83%E5%AE%9E%E6%88%98%E7%AF%87_%E5%BE%AE%E8%B0%83qwen%E5%9F%BA%E5%BA%A7%E6%A8%A1%E5%9E%8B%E5%85%B7%E5%A4%87reasoning%E6%80%9D%E8%80%83%E3%80%81%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%EF%BC%88%E7%B1%BB%E4%BC%BCo1%EF%BC%89.ipynb \"reasoning能力微调实战篇-微调qwen基座模型具备reasoning思考、推理能力（类似o1）\")\n\n- 这里需要特别指出：因为训练数据集主要是推理数据集，其数据风格比较统一（数据丰富度不够），训练过程能比较快的收敛，但是应该一定的过拟合现象，所以训练过程中损失才下降的这么低\n\n![损失记录.png](https://github.com/Paul33333/tinymind-blog/blob/main/assets/images/2024-10-14/1728895712564.png?raw=true)\n\n------\n\n## 3、reasoning效果测试\n测试模型的reasoning效果时，对比原始的直接推理`assistant`部分的回答，新的推理方案应为两步法（虽然训练环节时，我们采用了一步法统一考虑reasoning和assiatant的损失），具体如下：\n- 1、先基于问题推理reasoning回答\n- 2、reasoning完成后，将question和reasoning的回答一并再作为**input**送进去模型生成思考后的回答（assistant answer）\n\n具体实现如下：\n```python\nfrom IPython.display import Markdown, display\nhistory = []\nhistory.append({\"role\": \"system\", \"content\": \"You are a helpful assistant\"})\nwhile True:\n    question = input('User：' + '\\n')\n    print('\\n')\n    history.append({\"role\": \"user\", \"content\": question})\n    input_text = new_apply_chat_template(\n            history,\n            add_reasoning_generation_prompt=True\n        )\n    model_inputs = tokenizer([input_text], return_tensors=\"pt\").to(device)\n    if model_inputs.input_ids.size()[1]>32000:\n        break\n    generated_ids = model.generate(\n        model_inputs.input_ids,\n        max_new_tokens=3000\n    )\n    if len(generated_ids)>32000:\n        break\n    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]\n    reasoning_response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n    history.append({\"role\": \"<|reasoning|>\", \"content\": reasoning_response})\n    print('reasoning:\\n')\n    #print(response)\n    display(Markdown(reasoning_response))\n    print(\"------------\")\n    print('\\n')\n    input_text = new_apply_chat_template(\n            history,\n            add_assistant_generation_prompt=True\n        )\n    model_inputs = tokenizer([input_text], return_tensors=\"pt\").to(device)\n    if model_inputs.input_ids.size()[1]>32000:\n        break\n    generated_ids = model.generate(\n        model_inputs.input_ids,\n        max_new_tokens=3000\n    )\n    if len(generated_ids)>32000:\n        break\n    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]\n    assistant_response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n    history.append({\"role\": \"assistant\", \"content\": assistant_response})\n    print('assistant:\\n')\n    display(Markdown(assistant_response))\n    print(\"------------\")\nprint(\"超过模型字数上线，已退出\")\n```\n\n测试效果如下：\n\n![微调模型推理能力1.png](https://github.com/Paul33333/tinymind-blog/blob/main/assets/images/2024-10-14/1728896138728.png?raw=true)\n\n![微调模型推理能力2.png](https://github.com/Paul33333/tinymind-blog/blob/main/assets/images/2024-10-14/1728896152137.png?raw=true)\n\n可以看到模型在回答**找出0-10内的所有质数**这个问题时的reasoning详细推理步骤（推理思维链真长...）\n\n\n",
    "timestamp": "2024-10-14T12:45:51.314Z"
  }
]